/** Text classification models array */
export const TEXT_CLASSIFICATION_MODELS = [
    /** DistilBERT model fine-tuned on SST-2 dataset, quantized to int8 */
    '@cf/huggingface/distilbert-sst-2-int8',
];
/** Text-to-image generation models array */
export const TEXT_TO_IMAGE_MODELS = [
    /** Stability AI's SDXL 1.0 base model for high-quality image generation */
    '@cf/stabilityai/stable-diffusion-xl-base-1.0',
    /** Runway's SD 1.5 model specialized for image inpainting */
    '@cf/runwayml/stable-diffusion-v1-5-inpainting',
    /** Runway's SD 1.5 model for image-to-image transformation */
    '@cf/runwayml/stable-diffusion-v1-5-img2img',
    /** DreamShaper v8 with Latent Consistency Model for faster inference */
    '@cf/lykon/dreamshaper-8-lcm',
    /** ByteDance's optimized SDXL for faster generation */
    '@cf/bytedance/stable-diffusion-xl-lightning',
];
/** Text embeddings models array */
export const TEXT_EMBEDDINGS_MODELS = [
    /** BGE small English model v1.5 - efficient with good performance */
    '@cf/baai/bge-small-en-v1.5',
    /** BGE base English model v1.5 - balanced size and performance */
    '@cf/baai/bge-base-en-v1.5',
    /** BGE large English model v1.5 - highest quality embeddings */
    '@cf/baai/bge-large-en-v1.5',
];
/** Speech recognition models array */
export const SPEECH_RECOGNITION_MODELS = [
    /** OpenAI's Whisper base model for multilingual speech recognition */
    '@cf/openai/whisper',
    /** Tiny English-specific Whisper model for efficient processing */
    '@cf/openai/whisper-tiny-en',
    /** Sherpa-optimized Whisper variant */
    '@cf/openai/whisper-sherpa',
];
/** Image classification models array */
export const IMAGE_CLASSIFICATION_MODELS = [
    /** Microsoft's ResNet-50 model for general image classification */
    '@cf/microsoft/resnet-50',
];
/** Object detection models array */
export const OBJECT_DETECTION_MODELS = [
    /** Facebook's DETR (Detection Transformer) with ResNet-50 backbone */
    '@cf/facebook/detr-resnet-50',
];
/** Text generation models array */
export const TEXT_GENERATION_MODELS = [
    // Meta's LLaMA family
    /** LLaMA 3.1 8B instruction-tuned model */
    '@cf/meta/llama-3.1-8b-instruct',
    /** LLaMA 3 8B instruction-tuned model */
    '@cf/meta/llama-3-8b-instruct',
    /** LLaMA 3 8B instruction model with AWQ quantization */
    '@cf/meta/llama-3-8b-instruct-awq',
    /** LLaMA 2 7B chat model with INT8 quantization */
    '@cf/meta/llama-2-7b-chat-int8',
    /** LLaMA 2 7B chat model in FP16 format */
    '@cf/meta/llama-2-7b-chat-fp16',
    /** LLaMA 2 7B chat model with LoRA fine-tuning */
    '@cf/meta-llama/llama-2-7b-chat-hf-lora',
    /** LLaMA 3.1 70B instruction-tuned model */
    '@cf/meta/llama-3.1-70b-instruct',
    /** LLaMA 3.3 70B instruction-tuned model */
    '@cf/meta/llama-3.3-70b-instruct-fp8-fast',
    // Mistral AI models
    /** Mistral 7B instruction model v0.1 */
    '@cf/mistral/mistral-7b-instruct-v0.1',
    /** Mistral 7B instruction model v0.2 with LoRA */
    '@cf/mistral/mistral-7b-instruct-v0.2-lora',
    /** Mistral 7B instruction model v0.2 */
    '@hf/mistral/mistral-7b-instruct-v0.2',
    // TheBloke's optimized models
    /** LLaMA 2 13B chat model with AWQ quantization */
    '@hf/thebloke/llama-2-13b-chat-awq',
    /** Zephyr 7B beta model with AWQ quantization */
    '@hf/thebloke/zephyr-7b-beta-awq',
    /** Mistral 7B instruction v0.1 with AWQ */
    '@hf/thebloke/mistral-7b-instruct-v0.1-awq',
    /** CodeLLaMA 7B instruction model with AWQ */
    '@hf/thebloke/codellama-7b-instruct-awq',
    /** OpenHermes 2.5 Mistral 7B with AWQ */
    '@hf/thebloke/openhermes-2.5-mistral-7b-awq',
    /** NeuralChat 7B v3.1 with AWQ */
    '@hf/thebloke/neural-chat-7b-v3-1-awq',
    /** LLamaGuard 7B safety model with AWQ */
    '@hf/thebloke/llamaguard-7b-awq',
    /** DeepSeek Coder 6.7B base with AWQ */
    '@hf/thebloke/deepseek-coder-6.7b-base-awq',
    /** DeepSeek Coder 6.7B instruction with AWQ */
    '@hf/thebloke/deepseek-coder-6.7b-instruct-awq',
    /** German DiscoLM 7B v1 with AWQ */
    '@cf/thebloke/discolm-german-7b-v1-awq',
    // Google's Gemma models
    /** Gemma 7B instruction-tuned model */
    '@hf/google/gemma-7b-it',
    /** Gemma 2B instruction model with LoRA */
    '@cf/google/gemma-2b-it-lora',
    /** Gemma 7B instruction model with LoRA */
    '@cf/google/gemma-7b-it-lora',
    // Specialized models
    /** DeepSeek Math 7B instruction model */
    '@cf/deepseek-ai/deepseek-math-7b-instruct',
    /** SQLCoder 7B v2 for SQL generation */
    '@cf/defog/sqlcoder-7b-2',
    /** OpenChat 3.5 model (January 2024) */
    '@cf/openchat/openchat-3.5-0106',
    /** Falcon 7B instruction model */
    '@cf/tiiuae/falcon-7b-instruct',
    /** Hermes 2 Pro Mistral 7B */
    '@hf/nousresearch/hermes-2-pro-mistral-7b',
    /** Starling LM 7B beta */
    '@hf/nexusflow/starling-lm-7b-beta',
    // Qwen models
    /** Qwen 1.5 0.5B chat model */
    '@cf/qwen/qwen1.5-0.5b-chat',
    /** Qwen 1.5 1.8B chat model */
    '@cf/qwen/qwen1.5-1.8b-chat',
    /** Qwen 1.5 7B chat with AWQ */
    '@cf/qwen/qwen1.5-7b-chat-awq',
    /** Qwen 1.5 14B chat with AWQ */
    '@cf/qwen/qwen1.5-14b-chat-awq',
    // Other models
    /** TinyLLaMA 1.1B chat model v1.0 */
    '@cf/tinyllama/tinyllama-1.1b-chat-v1.0',
    /** Microsoft Phi-2 model */
    '@cf/microsoft/phi-2',
    /** Una Cybertron 7B v2 in BF16 format */
    '@cf/fblgit/una-cybertron-7b-v2-bf16',
    /** Una Cybertron 7B v2 with AWQ */
    '@cf/fblgit/una-cybertron-7b-v2-awq',
];
/** Text translation models array */
export const TRANSLATION_MODELS = [
    /** Meta's Many-to-Many multilingual translation model (1.2B parameters) */
    '@cf/meta/m2m100-1.2b',
];
/** Text summarization models array */
export const SUMMARIZATION_MODELS = [
    /** Facebook's BART model fine-tuned on CNN news articles for summarization */
    '@cf/facebook/bart-large-cnn',
];
/** Image-to-text generation models array */
export const IMAGE_TO_TEXT_MODELS = [
    /** Unum's UForm Gen2 model based on Qwen architecture (500M parameters) */
    '@cf/unum/uform-gen2-qwen-500m',
    /** LLaVA 1.5 multimodal model for image understanding and generation */
    '@cf/llava-hf/llava-1.5-7b-hf',
];
